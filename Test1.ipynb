{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a285e8b0",
   "metadata": {},
   "source": [
    "### Import a bunch of stuff to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9f58c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from fomlads.data.external import import_for_classification\n",
    "from fomlads.model.classification import project_data\n",
    "from fomlads.model.classification import maximum_separation_projection\n",
    "\n",
    "from fomlads.plot.exploratory import plot_scatter_array_classes\n",
    "from fomlads.plot.exploratory import plot_class_histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577d62b",
   "metadata": {},
   "source": [
    "### Collect and read the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68a0c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe.columns = Index(['popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
      "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
      "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
      "       'track_genre'],\n",
      "      dtype='object')\n",
      "input_cols = Index(['popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
      "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
      "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'],\n",
      "      dtype='object')\n",
      "classes = array(['classical', 'hip-hop', 'pop', 'r-n-b', 'edm', 'rock', 'acoustic',\n",
      "       'house', 'jazz'], dtype=object)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7000, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source = 'Data/Processed_data_training.csv'\n",
    "inputs, targets, field_names, classes = import_for_classification(data_source)\n",
    "\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48e45bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## D,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbffc39",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3225442818.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/f9/88_2t8j106d11pk5vg4h3q_h0000gn/T/ipykernel_3093/3225442818.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    split = sample.split(dataset$track_genre, SplitRatio = 2/5)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "find_dataset = 'Data/Processed_data.csv'\n",
    "dataset = pd.read_csv(find_dataset)\n",
    "\n",
    "## library(caTools)\n",
    "## split = sample.split(dataset$track_genre, SplitRatio = 2/5)\n",
    "## training_set = subset(dataset, split == TRUE)\n",
    "## test_set = subset(dataset, split == FALSE)\n",
    "## regressor = lm(formula = track_genre ~ popularity, data = training_set)\n",
    "## summary(regressor)\n",
    "\n",
    "## From unit 2, question 2.3b)\n",
    "train_filter = np.array([True if (i%2 == 0) else False for i in range(10000)])\n",
    "train_filter = np.random.choice([False, True], 10000, p = [0.4, 0.6])\n",
    "test_filter = ~train_filter\n",
    "\n",
    "from fomlads.evaluate.eval_regression import train_and_test_partition\n",
    "inputs_train, targets_train, inputs_test, targets_test = train_and_test_partition(inputs, targets, train_filter, test_filter)\n",
    "\n",
    "## From website\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression()\n",
    "reg.fit(inputs_train, targets_train) ##if not, try reg.fit(training values of popularity, training values of genre)\n",
    "prediction = reg.predict(inputs_test)\n",
    "accuracy = reg.score(inputs_test, targets_test) ## or accuracy = reg.score(prediction, targets_test)\n",
    "print(accuracy)\n",
    "\n",
    "## From stackoverflow\n",
    "from sklearn.metrics import accuracy_score\n",
    "prediction = reg.predict(inputs_test)\n",
    "score = accuracy_score(prediction, targets_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
